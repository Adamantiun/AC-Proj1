{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Mining Project - WNBA Playoffs prediction\n",
    "\n",
    "### Project developed by:\n",
    "- Adam Nogueira (up202007519)\n",
    "- Eduardo Silva (up202004999)\n",
    "- João Félix (up202008867)\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "\n",
    "\n",
    "### Introduction\n",
    "This project involves developing a data mining case study, which is described in a separate document provided on Moodle. The main focus of the project is a predictive data mining task, the details of which are outlined in the case study description.\n",
    "\n",
    "### Bibliography\n",
    "NumPy Developers, Numpy documentation, URL: https://numpy.org/doc/stable/user/index.html#user <br>\n",
    "pandas development team, pandas documentation, URL: https://pandas.pydata.org/docs/user_guide/index.html#user-guide<br>\n",
    "Matplotlib Development team, Matplotlib documentation, URL: https://matplotlib.org/stable/index.html <br>\n",
    "scikit-learn developers, scikit-learn documentation, URL: https://scikit-learn.org/0.18/documentation.html<br>\n",
    "\n",
    "### Approach\n",
    "\n",
    "The approach to this project was done as follows:\n",
    "\n",
    "1. **Data analysis**: First we analyzed the dataset to inspect for the need for data pre-processing: checked the corresponding histograms, class distribution, and the existence of missing or null values.\n",
    "2. **Algorithm implementation**: Flowing that, we defined the training and test sets using train/test split, resampled the dataset, and applied the SciKit Learn's algorithms to obtain the first results.\n",
    "3. **Evaluation and refinement**: After analyzing the first results, tunning of each algorithm was done utilizing the SciKit Learn GridSearchCV to find the parameters of each algorithm that yielded the best overall results, and evaluated the final results.\n",
    "\n",
    "### Used Libraries\n",
    "\n",
    "- **NumPy**: Provides a fast numerical array structure and helper functions.\n",
    "- **pandas**: Provides a DataFrame structure to store data in memory and work with it easily and efficiently.\n",
    "- **matplotlib**: The essential Machine Learning package in Python.\n",
    "- **sklearn**: Basic plotting library in Python; most other Python plotting libraries are built on top of it.\n",
    "- **seaborn**: Advanced statistical plotting library.\n",
    "- **pycaret**: Offers streamlined workflows and a wide range of pre-built algorithms and techniques to experiment with different models and compare their performance using different evaluation metrics.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data analysis\n",
    "\n",
    "We start by importing the required libraries and plotting some graphs for initial analysis of the dataset.\n",
    "\n",
    "### Key Statistics\n",
    "\n",
    "- Win-Loss Record: This is the most straightforward indicator. Teams with more wins are more likely to make the Playoff prediction predictions. Historically, teams with around a .500 or better win-loss record tend to have a good chance of making the playoffs.\n",
    "\n",
    "- Winning Percentage: Similar to win-loss record, winning percentage (Wins / Total Games) is a fundamental metric used to assess a team's performance.\n",
    "\n",
    "- Points Per Game (PPG): Teams that score more points on average are often more successful. This statistic reflects a team's offensive efficiency.\n",
    "\n",
    "- Points Allowed Per Game (PAPG): Teams that allow fewer points per game have a stronger defense. Defensive efficiency is a critical factor in determining playoff success.\n",
    "\n",
    "- Net Rating: Net rating is the difference between a team's offensive rating (points scored per 100 possessions) and their defensive rating (points allowed per 100 possessions). Teams with positive net ratings are often playoff-bound.\n",
    "\n",
    "- Field Goal Percentage (FG%): Shooting efficiency is a key factor in a team's offensive performance. A high field goal percentage indicates effective shooting.\n",
    "\n",
    "- Three-Point Percentage (3P%): The ability to make three-point shots is crucial in modern basketball. Teams with high three-point percentages often perform well.\n",
    "\n",
    "- Free Throw Percentage (FT%): Teams with good free throw shooting can close out close games more effectively.\n",
    "\n",
    "- Rebounds Per Game (RPG): Rebounding is a key component of both offense and defense. Teams that dominate the boards tend to have an advantage.\n",
    "\n",
    "- Assists Per Game (APG): Ball movement and sharing are critical in the NBA. Teams with high assist numbers often have a strong offense.\n",
    "\n",
    "- Steals and Blocks: Defensive statistics such as steals and blocks indicate a team's ability to disrupt the opponent's offense and protect the rim.\n",
    "\n",
    "- Turnovers: Reducing turnovers is important for maintaining possession and minimizing scoring opportunities for the opposition.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-13T11:17:43.243651300Z",
     "start_time": "2023-10-13T11:17:39.240954700Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imbalanced-learn in c:\\users\\utilizador\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.11.0)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\utilizador\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from imbalanced-learn) (1.24.3)\n",
      "Requirement already satisfied: scipy>=1.5.0 in c:\\users\\utilizador\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from imbalanced-learn) (1.10.1)\n",
      "Requirement already satisfied: scikit-learn>=1.0.2 in c:\\users\\utilizador\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from imbalanced-learn) (1.2.2)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\utilizador\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from imbalanced-learn) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\utilizador\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from imbalanced-learn) (3.1.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "     year  lgID tmID franchID confID  divID  rank playoff  seeded firstRound  \\\n",
      "0       9  WNBA  ATL      ATL     EA    NaN     7       N       0        NaN   \n",
      "1      10  WNBA  ATL      ATL     EA    NaN     2       Y       0          L   \n",
      "2       1  WNBA  CHA      CHA     EA    NaN     8       N       0        NaN   \n",
      "3       2  WNBA  CHA      CHA     EA    NaN     4       Y       0          W   \n",
      "4       3  WNBA  CHA      CHA     EA    NaN     2       Y       0          L   \n",
      "..    ...   ...  ...      ...    ...    ...   ...     ...     ...        ...   \n",
      "137     6  WNBA  WAS      WAS     EA    NaN     5       N       0        NaN   \n",
      "138     7  WNBA  WAS      WAS     EA    NaN     4       Y       0          L   \n",
      "139     8  WNBA  WAS      WAS     EA    NaN     5       N       0        NaN   \n",
      "140     9  WNBA  WAS      WAS     EA    NaN     6       N       0        NaN   \n",
      "141    10  WNBA  WAS      WAS     EA    NaN     4       Y       0          L   \n",
      "\n",
      "     ...  GP homeW homeL  awayW  awayL  confW  confL   min  attend  \\\n",
      "0    ...  34     1    16      3     14      2     18  6825  141379   \n",
      "1    ...  34    12     5      6     11     10     12  6950  120737   \n",
      "2    ...  32     5    11      3     13      5     16  6475   90963   \n",
      "3    ...  32    11     5      7      9     15      6  6500  105525   \n",
      "4    ...  32    11     5      7      9     12      9  6450  106670   \n",
      "..   ...  ..   ...   ...    ...    ...    ...    ...   ...     ...   \n",
      "137  ...  34    10     7      6     11      9     11  6900  171501   \n",
      "138  ...  34    13     4      5     12     12      8  6850  133255   \n",
      "139  ...  34     8     9      8      9      8     12  6900  133255   \n",
      "140  ...  34     6    11      4     13      6     14  6825  154637   \n",
      "141  ...  34    11     6      5     12     10     12  6875  192747   \n",
      "\n",
      "                  arena  \n",
      "0         Philips Arena  \n",
      "1         Philips Arena  \n",
      "2    Charlotte Coliseum  \n",
      "3    Charlotte Coliseum  \n",
      "4    Charlotte Coliseum  \n",
      "..                  ...  \n",
      "137      Verizon Center  \n",
      "138      Verizon Center  \n",
      "139      Verizon Center  \n",
      "140      Verizon Center  \n",
      "141      Verizon Center  \n",
      "\n",
      "[142 rows x 61 columns]\n"
     ]
    }
   ],
   "source": [
    "import data_manip\n",
    "import os\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from enum import Enum\n",
    "import seaborn as sb\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "#from pycaret.classification import *\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "%pip install imbalanced-learn\n",
    "\n",
    "\n",
    "# Set the warning filter to \"ignore\"\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "awards = pd.read_csv('original_data/awards_players.csv', na_values=['NA'], delimiter=\",\")\n",
    "coaches = pd.read_csv('original_data/coaches.csv', na_values=['NA'], delimiter=\",\")\n",
    "players = pd.read_csv('original_data/players.csv', na_values=['NA'], delimiter=\",\")\n",
    "players_teams = pd.read_csv('original_data/players_teams.csv', na_values=['NA'], delimiter=\",\")\n",
    "series_post = pd.read_csv('original_data/series_post.csv', na_values=['NA'], delimiter=\",\")\n",
    "teams = pd.read_csv('original_data/teams.csv', na_values=['NA'], delimiter=\",\")\n",
    "teams_post = pd.read_csv('original_data/teams_post.csv', na_values=['NA'], delimiter=\",\")\n",
    "\n",
    "\n",
    "print(teams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'convert_columns_to_ratio' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m player_teams_column_pairs \u001b[38;5;241m=\u001b[39m [(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfgMade\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfgAttempted\u001b[39m\u001b[38;5;124m'\u001b[39m), (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mftMade\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mftAttempted\u001b[39m\u001b[38;5;124m'\u001b[39m), (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mthreeMade\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mthreeAttempted\u001b[39m\u001b[38;5;124m'\u001b[39m)]\n\u001b[0;32m      4\u001b[0m player_teams_output_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodified_data/players_teams.csv\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m----> 5\u001b[0m \u001b[43mconvert_columns_to_ratio\u001b[49m(player_teams_input_path, player_teams_column_pairs, player_teams_output_path)\n\u001b[0;32m      7\u001b[0m player_teams_columns_to_exclude \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfgMade\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfgAttempted\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mftMade\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mftAttempted\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mthreeMade\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mthreeAttempted\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m      8\u001b[0m exclude_columns(player_teams_output_path, player_teams_columns_to_exclude, player_teams_output_path)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'convert_columns_to_ratio' is not defined"
     ]
    }
   ],
   "source": [
    "# PLAYERS_TEAMS\n",
    "player_teams_input_path = 'original_data/players_teams.csv'\n",
    "player_teams_column_pairs = [('fgMade', 'fgAttempted'), ('ftMade', 'ftAttempted'), ('threeMade', 'threeAttempted')]\n",
    "player_teams_output_path = 'modified_data/players_teams.csv'\n",
    "convert_columns_to_ratio(player_teams_input_path, player_teams_column_pairs, player_teams_output_path)\n",
    "\n",
    "player_teams_columns_to_exclude = ['fgMade', 'fgAttempted', 'ftMade', 'ftAttempted', 'threeMade', 'threeAttempted']\n",
    "exclude_columns(player_teams_output_path, player_teams_columns_to_exclude, player_teams_output_path)\n",
    "\n",
    "# TEAMS\n",
    "teams_input_path = 'original_data/teams.csv'\n",
    "teams_columns_to_exclude = ['confW', 'confL', 'min', 'attend', 'arena', 'tmORB', 'tmDRB', 'tmTRB', 'opptmORB', 'opptmDRB', 'opptmTRB', 'divID', 'seeded']\n",
    "teams_output_path = 'modified_data/teams.csv'\n",
    "\n",
    "exclude_columns(teams_input_path, teams_columns_to_exclude, teams_output_path)\n",
    "\n",
    "# PLAYERS\n",
    "players_input_path = 'original_data/players.csv'\n",
    "players_columns_to_exclude = ['firstseason', 'lastseason', 'height', 'weight', 'college', 'collegeOther', 'deathDate']\n",
    "players_output_path = 'modified_data/players.csv'\n",
    "exclude_columns(players_input_path, players_columns_to_exclude, players_output_path)\n",
    "\n",
    "column_mapping = {'bioID': 'playerID'}\n",
    "rename_columns(players_output_path, column_mapping, players_output_path)\n",
    "\n",
    "\n",
    "# AWARDS_PLAYERS\n",
    "players_input_path = 'original_data/awards_players.csv'\n",
    "players_columns_to_exclude = ['award', 'lgID']\n",
    "players_output_path = 'modified_data/awards_players.csv'\n",
    "exclude_columns(players_input_path, players_columns_to_exclude, players_output_path)\n",
    "\n",
    "# TEAMS_POST\n",
    "teams_input_path = 'original_data/teams_post.csv'\n",
    "teams_columns_to_exclude = ['lgID']\n",
    "teams_output_path = 'modified_data/teams_post.csv'\n",
    "\n",
    "exclude_columns(teams_input_path, teams_columns_to_exclude, teams_output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('modified_data/teams.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-13T11:13:58.600120800Z",
     "start_time": "2023-10-13T11:13:58.379867800Z"
    }
   },
   "outputs": [],
   "source": [
    "# Custom formatting function\n",
    "def custom_format(value):\n",
    "    # Check if the value is a number (int or float)\n",
    "    if isinstance(value, (int, float)):\n",
    "        # If it's an integer, format as an integer\n",
    "        if isinstance(value, int):\n",
    "            return value\n",
    "        # If it's a float, format with 2 decimal places\n",
    "        elif isinstance(value, float):\n",
    "            return round(value, 2)\n",
    "    else:\n",
    "        return value\n",
    "\n",
    "formatted_df = teams.applymap(custom_format)\n",
    "formatted_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking for null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-13T11:13:58.600120800Z",
     "start_time": "2023-10-13T11:13:58.509918400Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After examining the dataset and assessing its characteristics, we conducted a comprehensive analysis. The results revealed a high level of data consistency, with no missing values or notable outliers observed. As a consequence, the dataset demonstrated a remarkable level of readiness for analysis, requiring minimal data preprocessing efforts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-13T11:13:58.621598700Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and Test split data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dividimos os dados em conjunto de input e label para os classificadores do Scikit. Label é a coluna Class and input é as restantes colunas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-13T11:13:58.624924700Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset['playoff'] = dataset['playoff'].astype('category')\n",
    "\n",
    "col_names = list(dataset.columns)\n",
    "col_names.remove('name')\n",
    "col_names.remove('lgID')\n",
    "col_names.remove('tmID')\n",
    "col_names.remove('franchID')\n",
    "col_names.remove('confID')\n",
    "col_names.remove('firstRound')\n",
    "col_names.remove('semis')\n",
    "col_names.remove('finals')\n",
    "\n",
    "inputs = dataset[col_names].values\n",
    "labels = dataset['playoff'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resumidamente dividi dados em dados de teste e treinamento, mantendo a mesma distribuição das classes inicias, usando 1/4 do dataset original\n",
    "\n",
    "- stratify - para manter a distribuição de classes \n",
    "- train_in - variável que armazena as características de treinamento\n",
    "- test_in - variável que armazena as características de teste\n",
    "- train_classes - armazena as classes dos dados de treinamento\n",
    "- test_classes - armazena as classes dos dados de testes\n",
    "- random_state - para garantir randomness na divisão de dados\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-13T11:13:58.628505Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "(train_in,\n",
    " test_in,\n",
    " train_classes,\n",
    " test_classes) = train_test_split(inputs, labels, test_size=0.25, random_state=1, stratify=labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data analyses showed us that our working dataset is unbalanced. We implemented both undersampling and oversampling. Undersampling removes samples from majority categories, while oversampling duplicates samples from minority categories. Generally oversampling is preferred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conta a ocorrência de cada classe nos conjuntos de treinamento e teste. Da um overview da distribuição das classes em cada conunto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-13T11:13:58.628505Z"
    }
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "print(\"---Train Set---\")\n",
    "print(Counter(train_classes))\n",
    "print(\"\\n---Test Set---\")\n",
    "print(Counter(test_classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "É usado para balancear os dados. Remove aleatoriamente dados da classe com maior número de dados até que se encontro o equilíbrio que se quer. Undersampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-13T11:13:58.632829Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "rus = RandomUnderSampler()\n",
    "\n",
    "us_inputs, us_labels = rus.fit_resample(train_in, train_classes)\n",
    "\n",
    "print(Counter(us_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Faz oversampling dos dados e conseguimos ver que realmente os dados ficaram equilibradoos nos dados de treino. aumenta o número de linhas, tornando-a mais proporcionsl à classe maioritaria<>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-13T11:13:58.632829Z"
    }
   },
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "ros = SMOTE()\n",
    "\n",
    "os_inputs, os_labels = ros.fit_resample(train_in, train_classes)\n",
    "\n",
    "print(Counter(os_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We used a StandardScaler from SciKit Learn's preprocessing library to standardize the data. Porque é necessário para o K nearest neighbrs e o SVM\n",
    "\n",
    "Fas-se a padronização dos dados para garantir que as características contribuam igualmente para os modelos de machine learning, e evita que uma caraterística em particular dominee o processo de learning da outra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-13T11:13:58.638382Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler  \n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "scaler.fit(train_in)\n",
    "train_in = scaler.fit_transform(train_in)\n",
    "test_in = scaler.fit_transform(test_in)\n",
    "\n",
    "scaler.fit(os_inputs)\n",
    "os_inputs = scaler.fit_transform(os_inputs)\n",
    "\n",
    "scaler.fit(us_inputs)\n",
    "us_inputs = scaler.fit_transform(us_inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Original Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-13T11:13:58.640483400Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "classifier = KNeighborsClassifier()\n",
    "classifier.fit(train_in, train_classes)\n",
    "y_pred = classifier.predict(test_in)\n",
    "\n",
    "result = confusion_matrix(test_classes, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(result)\n",
    "result1 = classification_report(test_classes, y_pred)\n",
    "print(\"Classification Report:\",)\n",
    "print (result1) \n",
    "\n",
    "knn_og_report = classification_report(test_classes, y_pred,output_dict=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Undersampled Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-13T11:13:58.640483400Z"
    }
   },
   "outputs": [],
   "source": [
    "classifier = KNeighborsClassifier()\n",
    "classifier.fit(us_inputs, us_labels)\n",
    "y_pred = classifier.predict(test_in)\n",
    "\n",
    "knn_confusion_matrix = confusion_matrix(test_classes, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(knn_confusion_matrix)\n",
    "result1 = classification_report(test_classes, y_pred)\n",
    "print(\"Classification Report:\",)\n",
    "print(result1)\n",
    "\n",
    "knn_us_report = classification_report(test_classes, y_pred, output_dict=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Oversampled Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-13T11:13:58.647495200Z"
    }
   },
   "outputs": [],
   "source": [
    "classifier = KNeighborsClassifier()\n",
    "classifier.fit(os_inputs, os_labels)\n",
    "y_pred = classifier.predict(test_in)\n",
    "\n",
    "result = confusion_matrix(test_classes, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(result)\n",
    "result1 = classification_report(test_classes, y_pred)\n",
    "print(\"Classification Report:\",)\n",
    "print (result1)\n",
    "\n",
    "knn_os_report = classification_report(test_classes, y_pred,output_dict=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Original Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion matrix:\n",
    "TP FP\n",
    "TN FN\n",
    "FP = False Positive - deu que iam atrasar (1) mas na realidade é 0\n",
    "\n",
    "Precision - mede a proporção de dados corretamente calculado TP/(TP+FP)\n",
    "\n",
    "Accuracy - mede a correção no geral (TP + TN) / (TP + TN + FP + FN).\n",
    "    - em dados não balenciados pode ser misleading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-13T11:13:58.648933300Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dtc = DecisionTreeClassifier()\n",
    "\n",
    "dtc.fit(train_in, train_classes)\n",
    "dtc_prediction = dtc.predict(test_in)\n",
    "\n",
    "dtc_classification_report = classification_report(test_classes, dtc_prediction, output_dict=True)\n",
    "\n",
    "print(\"--- Original dataset ---\\n\")\n",
    "print(\"Confusion matrix:\")\n",
    "print(f\"{confusion_matrix(test_classes, dtc_prediction)}\\n\")\n",
    "print(f\"Classification report:\")\n",
    "print(f\"{classification_report(test_classes, dtc_prediction)}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Undersampled Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-13T11:13:58.648933300Z"
    }
   },
   "outputs": [],
   "source": [
    "dtc.fit(us_inputs, us_labels)\n",
    "dtc_prediction = dtc.predict(test_in)\n",
    "\n",
    "dtc_us_classification_report = classification_report(test_classes, dtc_prediction, output_dict=True)\n",
    "\n",
    "print(\"--- Undersampled dataset ---\\n\")\n",
    "print(f\"Confusion matrix:\\n{confusion_matrix(test_classes, dtc_prediction)}\\n\")\n",
    "print(f\"Classification report:\\n{classification_report(test_classes, dtc_prediction)}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Oversampled Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-13T11:13:58.658240300Z"
    }
   },
   "outputs": [],
   "source": [
    "dtc.fit(os_inputs, os_labels)\n",
    "dtc_prediction = dtc.predict(test_in)\n",
    "\n",
    "dtc_os_classification_report = classification_report(test_classes, dtc_prediction, output_dict=True)\n",
    "\n",
    "print(\"--- Oversampled dataset ---\\n\")\n",
    "print(f\"Confusion matrix:\\n{confusion_matrix(test_classes, dtc_prediction)}\\n\")\n",
    "print(f\"Classification report:\\n{classification_report(test_classes, dtc_prediction)}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Original Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-13T11:13:58.659552700Z"
    }
   },
   "outputs": [],
   "source": [
    "svc = SVC()\n",
    "\n",
    "svc.fit(train_in, train_classes)\n",
    "y_pred = svc.predict(test_in)\n",
    "\n",
    "result = confusion_matrix(test_classes, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(result)\n",
    "result1 = classification_report(test_classes, y_pred)\n",
    "print(\"Classification Report:\",)\n",
    "print (result1) \n",
    "\n",
    "svc_og_report = classification_report(test_classes, y_pred,output_dict=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Undersampled Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-13T11:13:58.659552700Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svc = SVC()\n",
    "\n",
    "svc.fit(us_inputs, us_labels)\n",
    "y_pred = svc.predict(test_in)\n",
    "\n",
    "result = confusion_matrix(test_classes, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(result)\n",
    "result1 = classification_report(test_classes, y_pred)\n",
    "print(\"Classification Report:\",)\n",
    "print (result1) \n",
    "\n",
    "svc_us_report = classification_report(test_classes, y_pred,output_dict=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Oversampled Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-13T11:13:58.665088400Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svc = SVC()\n",
    "\n",
    "svc.fit(os_inputs, os_labels)\n",
    "y_pred = svc.predict(test_in)\n",
    "\n",
    "result = confusion_matrix(test_classes, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(result)\n",
    "result1 = classification_report(test_classes, y_pred)\n",
    "print(\"Classification Report:\",)\n",
    "print (result1) \n",
    "\n",
    "svc_os_report = classification_report(test_classes, y_pred,output_dict=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result Analyses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-13T11:13:58.665088400Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "all_algorithms_data = pd.read_csv('models_comparison.csv', na_values=['NA'], delimiter=\",\")\n",
    "all_algorithms_data.set_index(\"Model\", inplace=True)\n",
    "\n",
    "sb.heatmap(all_algorithms_data, cmap=\"YlGnBu\", annot=True)\n",
    "plt.xlabel('Results')\n",
    "plt.ylabel('ML Models')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selected algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-13T11:13:58.668635500Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "selected_algorithms_data = pd.read_csv('models_comparison_selected.csv', na_values=['NA'], delimiter=\",\")\n",
    "selected_algorithms_data.set_index(\"Model\", inplace=True)\n",
    "\n",
    "sb.heatmap(selected_algorithms_data, cmap=\"YlGnBu\", annot=True)\n",
    "plt.xlabel('Results')\n",
    "plt.ylabel('ML Models')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing Accuracys of each algorythm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-13T11:13:58.668635500Z"
    }
   },
   "outputs": [],
   "source": [
    "selected_algorithms_data = selected_algorithms_data.sort_values(by=['Accuracy'], ascending=False)\n",
    "\n",
    "# Create the bar plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "sb.barplot(x=selected_algorithms_data.index, y='Accuracy', data=selected_algorithms_data, color='#A7226E')\n",
    "\n",
    "# Set the plot title and axis labels\n",
    "plt.title('Accuracy Comparison by Algorithm')\n",
    "plt.xlabel('Model')\n",
    "plt.ylabel('Accuracy')\n",
    "\n",
    "plt.xticks(rotation=90)\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing AUC (Area Under Curve) of each algorythm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-13T11:13:58.668635500Z"
    }
   },
   "outputs": [],
   "source": [
    "selected_algorithms_data = selected_algorithms_data.sort_values(by=['AUC'], ascending=False)\n",
    "\n",
    "# Create the bar plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "sb.barplot(x=selected_algorithms_data.index, y='AUC', data=selected_algorithms_data, color='#FE4365')\n",
    "\n",
    "# Set the plot title and axis labels\n",
    "plt.title('AUC Comparison by Algorithm')\n",
    "plt.xlabel('Model')\n",
    "plt.ylabel('AUC')\n",
    "\n",
    "plt.xticks(rotation=90)\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing Recall of each algorythm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-13T11:13:58.668635500Z"
    }
   },
   "outputs": [],
   "source": [
    "selected_algorithms_data = selected_algorithms_data.sort_values(by=['Recall'], ascending=False)\n",
    "\n",
    "# Create the bar plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "sb.barplot(x=selected_algorithms_data.index, y='Recall', data=selected_algorithms_data, color='#9DE0AD')\n",
    "\n",
    "# Set the plot title and axis labels\n",
    "plt.title('Recall Comparison by Algorithm')\n",
    "plt.xlabel('Model')\n",
    "plt.ylabel('Recall')\n",
    "\n",
    "plt.xticks(rotation=90)\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing Precision of each algorythm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-13T11:13:58.893868Z",
     "start_time": "2023-10-13T11:13:58.673637500Z"
    }
   },
   "outputs": [],
   "source": [
    "selected_algorithms_data = selected_algorithms_data.sort_values(by=['Precision'], ascending=False)\n",
    "\n",
    "# Create the bar plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "sb.barplot(x=selected_algorithms_data.index, y='Precision', data=selected_algorithms_data, color='#F7DB4F')\n",
    "\n",
    "# Set the plot title and axis labels\n",
    "plt.title('Precision Comparison by Algorithm')\n",
    "plt.xlabel('Model')\n",
    "plt.ylabel('Precision')\n",
    "\n",
    "plt.xticks(rotation=90)\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing F1-score of each algorythm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-13T11:13:58.673637500Z"
    }
   },
   "outputs": [],
   "source": [
    "selected_algorithms_data = selected_algorithms_data.sort_values(by=['F1'], ascending=False)\n",
    "\n",
    "# Create the bar plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "sb.barplot(x=selected_algorithms_data.index, y='F1', data=selected_algorithms_data, color='#F26B38')\n",
    "\n",
    "# Set the plot title and axis labels\n",
    "plt.title('F1-Score Comparison by Algorithm')\n",
    "plt.xlabel('Model')\n",
    "plt.ylabel('F1-Score')\n",
    "\n",
    "plt.xticks(rotation=90)\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing Kappa of each algorythm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-13T11:13:58.675723400Z"
    }
   },
   "outputs": [],
   "source": [
    "selected_algorithms_data = selected_algorithms_data.sort_values(by=['Kappa'], ascending=False)\n",
    "\n",
    "# Create the bar plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "sb.barplot(x=selected_algorithms_data.index, y='Kappa', data=selected_algorithms_data, color='#2F9599')\n",
    "\n",
    "# Set the plot title and axis labels\n",
    "plt.title('Kappa Comparison by Algorithm')\n",
    "plt.xlabel('Model')\n",
    "plt.ylabel('Kappa')\n",
    "\n",
    "plt.xticks(rotation=90)\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing Matthews Correlation Coefficient of each algorythm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-13T11:13:58.677950400Z"
    }
   },
   "outputs": [],
   "source": [
    "selected_algorithms_data = selected_algorithms_data.sort_values(by=['MCC'], ascending=False)\n",
    "\n",
    "# Create the bar plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "sb.barplot(x=selected_algorithms_data.index, y='MCC', data=selected_algorithms_data, color='#FF4E50')\n",
    "\n",
    "# Set the plot title and axis labels\n",
    "plt.title('Matthews Correlation Coefficient Comparison by Algorithm')\n",
    "plt.xlabel('Model')\n",
    "plt.ylabel('Matthews Correlation Coefficient')\n",
    "\n",
    "plt.xticks(rotation=90)\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing Training Time (sec) of each algorythm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-13T11:13:58.678506400Z"
    }
   },
   "outputs": [],
   "source": [
    "selected_algorithms_data = selected_algorithms_data.sort_values(by=['TT (Sec)'], ascending=False)\n",
    "\n",
    "# Create the bar plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "sb.barplot(x=selected_algorithms_data.index, y='TT (Sec)', data=selected_algorithms_data, color='#9DE0AD')\n",
    "\n",
    "# Set the plot title and axis labels\n",
    "plt.title('Training Time comparison by Algorithm')\n",
    "plt.xlabel('Model')\n",
    "plt.ylabel('Training Time (Sec)')\n",
    "\n",
    "plt.xticks(rotation=90)\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
