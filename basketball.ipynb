{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Airlines Delay\n",
    "\n",
    "### Project developed by:\n",
    "- Adam Nogueira (up202007519)\n",
    "- Eduardo Silva (up202004999)\n",
    "- João Félix (up202008867)\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "\n",
    "\n",
    "## Introduction\n",
    "This project involves developing a data mining case study, which is described in a separate document provided on Moodle. The main focus of the project is a predictive data mining task, the details of which are outlined in the case study description.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### Bibliography\n",
    "NumPy Developers, Numpy documentation, URL: https://numpy.org/doc/stable/user/index.html#user <br>\n",
    "pandas development team, pandas documentation, URL: https://pandas.pydata.org/docs/user_guide/index.html#user-guide<br>\n",
    "Matplotlib Development team, Matplotlib documentation, URL: https://matplotlib.org/stable/index.html <br>\n",
    "scikit-learn developers, scikit-learn documentation, URL: https://scikit-learn.org/0.18/documentation.html<br>\n",
    "\n",
    "### Approach\n",
    "\n",
    "The approach to this project was done as follows:\n",
    "\n",
    "1. **Data analysis**: First we analyzed the dataset to inspect for the need for data pre-processing: checked the corresponding histograms, class distribution, and the existence of missing or null values.\n",
    "2. **Algorithm implementation**: Flowing that, we defined the training and test sets using train/test split, resampled the dataset, and applied the SciKit Learn's algorithms to obtain the first results.\n",
    "3. **Evaluation and refinement**: After analyzing the first results, tunning of each algorithm was done utilizing the SciKit Learn GridSearchCV to find the parameters of each algorithm that yielded the best overall results, and evaluated the final results.\n",
    "\n",
    "### Used Libraries\n",
    "\n",
    "- **NumPy**: Provides a fast numerical array structure and helper functions.\n",
    "- **pandas**: Provides a DataFrame structure to store data in memory and work with it easily and efficiently.\n",
    "- **matplotlib**: The essential Machine Learning package in Python.\n",
    "- **sklearn**: Basic plotting library in Python; most other Python plotting libraries are built on top of it.\n",
    "- **seaborn**: Advanced statistical plotting library.\n",
    "- **pycaret**: Offers streamlined workflows and a wide range of pre-built algorithms and techniques to experiment with different models and compare their performance using different evaluation metrics.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data analysis\n",
    "\n",
    "We start by importing the required libraries and plotting some graphs for initial analysis of the dataset.\n",
    "\n",
    "### Key Statistics\n",
    "\n",
    "- Win-Loss Record: This is the most straightforward indicator. Teams with more wins are more likely to make the playoffs. Historically, teams with around a .500 or better win-loss record tend to have a good chance of making the playoffs.\n",
    "\n",
    "- Winning Percentage: Similar to win-loss record, winning percentage (Wins / Total Games) is a fundamental metric used to assess a team's performance.\n",
    "\n",
    "- Points Per Game (PPG): Teams that score more points on average are often more successful. This statistic reflects a team's offensive efficiency.\n",
    "\n",
    "- Points Allowed Per Game (PAPG): Teams that allow fewer points per game have a stronger defense. Defensive efficiency is a critical factor in determining playoff success.\n",
    "\n",
    "- Net Rating: Net rating is the difference between a team's offensive rating (points scored per 100 possessions) and their defensive rating (points allowed per 100 possessions). Teams with positive net ratings are often playoff-bound.\n",
    "\n",
    "- Field Goal Percentage (FG%): Shooting efficiency is a key factor in a team's offensive performance. A high field goal percentage indicates effective shooting.\n",
    "\n",
    "- Three-Point Percentage (3P%): The ability to make three-point shots is crucial in modern basketball. Teams with high three-point percentages often perform well.\n",
    "\n",
    "- Free Throw Percentage (FT%): Teams with good free throw shooting can close out close games more effectively.\n",
    "\n",
    "- Rebounds Per Game (RPG): Rebounding is a key component of both offense and defense. Teams that dominate the boards tend to have an advantage.\n",
    "\n",
    "- Assists Per Game (APG): Ball movement and sharing are critical in the NBA. Teams with high assist numbers often have a strong offense.\n",
    "\n",
    "- Steals and Blocks: Defensive statistics such as steals and blocks indicate a team's ability to disrupt the opponent's offense and protect the rim.\n",
    "\n",
    "- Turnovers: Reducing turnovers is important for maintaining possession and minimizing scoring opportunities for the opposition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-13T11:17:43.243651300Z",
     "start_time": "2023-10-13T11:17:39.240954700Z"
    }
   },
   "outputs": [],
   "source": [
    "import data_manip\n",
    "import os\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from enum import Enum\n",
    "import seaborn as sb\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "#from pycaret.classification import *\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "%pip install imbalanced-learn\n",
    "\n",
    "\n",
    "# Set the warning filter to \"ignore\"\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "awards = pd.read_csv('modified_data/awards_players.csv', na_values=['NA'], delimiter=\",\")\n",
    "coaches = pd.read_csv('modified_data/coaches.csv', na_values=['NA'], delimiter=\",\")\n",
    "players = pd.read_csv('modified_data/players.csv', na_values=['NA'], delimiter=\",\")\n",
    "players_teams = pd.read_csv('modified_data/players_teams.csv', na_values=['NA'], delimiter=\",\")\n",
    "series_post = pd.read_csv('modified_data/series_post.csv', na_values=['NA'], delimiter=\",\")\n",
    "teams = pd.read_csv('modified_data/teams.csv', na_values=['NA'], delimiter=\",\")\n",
    "teams_post = pd.read_csv('modified_data/teams_post.csv', na_values=['NA'], delimiter=\",\")\n",
    "\n",
    "\n",
    "print(teams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-13T11:13:58.600120800Z",
     "start_time": "2023-10-13T11:13:58.379867800Z"
    }
   },
   "outputs": [],
   "source": [
    "# Custom formatting function\n",
    "def custom_format(value):\n",
    "    # Check if the value is a number (int or float)\n",
    "    if isinstance(value, (int, float)):\n",
    "        # If it's an integer, format as an integer\n",
    "        if isinstance(value, int):\n",
    "            return value\n",
    "        # If it's a float, format with 2 decimal places\n",
    "        elif isinstance(value, float):\n",
    "            return round(value, 2)\n",
    "    else:\n",
    "        return value\n",
    "\n",
    "formatted_df = teams.applymap(custom_format)\n",
    "formatted_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Playoff appearences by team"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "teams_df = pd.read_csv('./modified_data/teams.csv')\n",
    "\n",
    "playoff_teams = teams_df[teams_df['playoff'] == 'Y']\n",
    "\n",
    "playoff_count = playoff_teams['name'].value_counts().reset_index()\n",
    "playoff_count.columns = ['Team', 'Playoff Appearances']\n",
    "\n",
    "playoff_count = playoff_count.sort_values(by='Playoff Appearances', ascending=False)\n",
    "print(playoff_count)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(playoff_count['Team'], playoff_count['Playoff Appearances'])\n",
    "plt.xlabel('Team')\n",
    "plt.ylabel('Playoff Appearances')\n",
    "plt.title('Playoff Appearances per Team')\n",
    "plt.xticks(rotation=90) \n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Average players age per team"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "players_df = pd.read_csv('./modified_data/players.csv')\n",
    "players_teams_df = pd.read_csv('./modified_data/players_teams.csv')\n",
    "teams_df = pd.read_csv('./modified_data/teams.csv')\n",
    "\n",
    "players_df = players_df[~players_df['birthDate'].str.startswith('0000')]\n",
    "\n",
    "players_df['birthYear'] = players_df['birthDate'].str[:4].astype(int)\n",
    "players_df['idade'] = 2023 - players_df['birthYear']\n",
    "\n",
    "players_teams_df = players_teams_df[players_teams_df['year'] == 10]\n",
    "\n",
    "merged_df = players_teams_df.merge(players_df, left_on='playerID', right_on='bioID')\n",
    "\n",
    "team_avg_age = merged_df.groupby('tmID')['idade'].mean().reset_index()\n",
    "\n",
    "team_avg_age = team_avg_age.merge(teams_df, left_on='tmID', right_on='tmID')\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(team_avg_age['name'], team_avg_age['idade'])\n",
    "plt.xlabel('Team')\n",
    "plt.ylabel('Average age')\n",
    "plt.title('Average players age per team (Year 10)')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Win-Loss Record (Year 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Win-Loss Rate\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data = pd.read_csv(\"./modified_data/teams.csv\")\n",
    "\n",
    "data_year_10 = data[data['year'] == 10]\n",
    "\n",
    "team_records = data_year_10.groupby('name')[['won', 'lost']].sum().reset_index()\n",
    "\n",
    "team_records['win_loss_rate'] = team_records['won'] / (team_records['won'] + team_records['lost'])\n",
    "\n",
    "team_records = team_records.sort_values(by='win_loss_rate', ascending=False)\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.barh(team_records['name'], team_records['win_loss_rate'])\n",
    "plt.xlabel('Win-Loss Rate')\n",
    "plt.ylabel('Team')\n",
    "plt.title('Win-Loss Rate of All Teams in Year 10')\n",
    "plt.grid(axis='x')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Winning Percentage last 10 years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data = pd.read_csv(\"./modified_data/teams.csv\")\n",
    "\n",
    "last_10_years = data[data['year'] >= data['year'].max() - 9]\n",
    "\n",
    "team_records = last_10_years.groupby('name')[['won', 'lost']].sum().reset_index()\n",
    "\n",
    "team_records['win_percentage'] = (team_records['won'] / (team_records['won'] + team_records['lost'])) * 100\n",
    "\n",
    "team_records = team_records.sort_values(by='win_percentage', ascending=False)\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.barh(team_records['name'], team_records['win_percentage'])\n",
    "plt.xlabel('Win Percentage (%)')\n",
    "plt.ylabel('Team')\n",
    "plt.title('Win Percentage of All Teams in the Last 10 Years')\n",
    "plt.grid(axis='x')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Winning Percentage Year 10 only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data = pd.read_csv(\"./modified_data/teams.csv\")\n",
    "\n",
    "data_year_10 = data[data['year'] == 10]\n",
    "\n",
    "team_records = data_year_10.groupby('name')[['won', 'lost']].sum().reset_index()\n",
    "\n",
    "team_records['win_percentage'] = (team_records['won'] / (team_records['won'] + team_records['lost'])) * 100\n",
    "\n",
    "team_records = team_records.sort_values(by='win_percentage', ascending=False)\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.barh(team_records['name'], team_records['win_percentage'], color='skyblue')\n",
    "plt.xlabel('Win Percentage (%)')\n",
    "plt.ylabel('Team')\n",
    "plt.title('Win Percentage of All Teams in year 10')\n",
    "plt.grid(axis='x')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Points per Game (PPG) Year 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"./modified_data/teams.csv\")\n",
    "\n",
    "df= df[df['year'] == 10]\n",
    "\n",
    "df['PPG'] = (df['o_pts'] / df['GP']).round()\n",
    "\n",
    "result = df[['name', 'PPG']]\n",
    "result.columns= ['Team', 'PointsPerGame']\n",
    "\n",
    "result = result.sort_values(by='PointsPerGame', ascending=False)\n",
    "\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Net Rating (Year 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data = pd.read_csv(\"./modified_data/teams.csv\")\n",
    "\n",
    "data_year_10 = data[data['year'] == 10]\n",
    "\n",
    "team_records = data_year_10.groupby('name')[['o_fgm', 'o_fga']].sum().reset_index()\n",
    "\n",
    "team_records['percentage'] = ((team_records['o_fgm']) / (team_records['o_fga']))* 100\n",
    "\n",
    "team_records = team_records.sort_values(by='percentage', ascending=False)\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.barh(team_records['name'], team_records['percentage'], color='skyblue')\n",
    "plt.xlabel('Percentage (%)')\n",
    "plt.ylabel('Team')\n",
    "plt.title('Net Rating (Year 10)')\n",
    "plt.grid(axis='x')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Field Goal Percentage (FG%) Year 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.read_csv(\"./modified_data/teams.csv\")\n",
    "\n",
    "df = df[df['year'] == 10]\n",
    "\n",
    "df['FG%'] = (df['o_fgm'] / df['o_fga']) * 100\n",
    "\n",
    "fg_percentages = df.groupby('name')['FG%'].mean().reset_index()\n",
    "result = fg_percentages.sort_values(by='FG%', ascending=False)\n",
    "\n",
    "\n",
    "print(result)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Three Points Percentage (FT%) Year 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.read_csv(\"./modified_data/teams.csv\")\n",
    "\n",
    "df = df[df['year'] == 10]\n",
    "\n",
    "df['3P%'] = (df['o_3pm'] / df['o_3pa']) * 100\n",
    "\n",
    "fg_percentages = df.groupby('name')['3P%'].mean().reset_index()\n",
    "result = fg_percentages.sort_values(by='3P%', ascending=False)\n",
    "\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Free Throw Percentage (FT%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.read_csv(\"./modified_data/teams.csv\")\n",
    "\n",
    "df = df[df['year'] == 10]\n",
    "\n",
    "df['FT%'] = (df['o_ftm'] / df['o_fta']) * 100\n",
    "\n",
    "fg_percentages = df.groupby('name')['FT%'].mean().reset_index()\n",
    "result = fg_percentages.sort_values(by='FT%', ascending=False)\n",
    "\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rebounds per Game (RPG) Year 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.read_csv(\"./modified_data/teams.csv\")\n",
    "\n",
    "df = df[df['year'] == 10]\n",
    "\n",
    "df['Rebounds'] = (df['o_reb'] + df['d_reb'])/ df['GP']\n",
    "\n",
    "fg_percentages = df.groupby('name')['Rebounds'].mean().reset_index()\n",
    "result = fg_percentages.sort_values(by='Rebounds', ascending=False)\n",
    "\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assists per Game (APG) Year 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.read_csv(\"./modified_data/teams.csv\")\n",
    "\n",
    "df = df[df['year'] == 10]\n",
    "\n",
    "df['Assists'] = (df['o_asts'])/ df['GP']\n",
    "\n",
    "fg_percentages = df.groupby('name')['Assists'].mean().reset_index()\n",
    "result = fg_percentages.sort_values(by='Assists', ascending=False)\n",
    "\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Steals and Blocks per Game (Year 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.read_csv(\"./modified_data/teams.csv\")\n",
    "\n",
    "df = df[df['year'] == 10]\n",
    "\n",
    "df['Steals and Blocks'] = (df['d_stl'] + df['d_blk']) / df['GP']\n",
    "\n",
    "fg_percentages = df.groupby('name')['Steals and Blocks'].mean().reset_index()\n",
    "result = fg_percentages.sort_values(by='Steals and Blocks', ascending=False)\n",
    "\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Turnovers (Year 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.read_csv(\"./modified_data/teams.csv\")\n",
    "\n",
    "df = df[df['year'] == 10]\n",
    "\n",
    "df['Turnovers'] = (df['d_to']) / df['GP']\n",
    "\n",
    "fg_percentages = df.groupby('name')['Turnovers'].mean().reset_index()\n",
    "result = fg_percentages.sort_values(by='Turnovers', ascending=False)\n",
    "\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All tables together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        name  Turnovers  Steals and Blocks    Assists   \n",
      "0              Atlanta Dream  17.676471          14.117647  16.088235  \\\n",
      "1                Chicago Sky  14.382353          11.588235  15.647059   \n",
      "2            Connecticut Sun  16.147059          10.970588  17.882353   \n",
      "3              Detroit Shock  15.617647          11.441176  16.911765   \n",
      "4              Indiana Fever  18.764706          11.382353  15.500000   \n",
      "5         Los Angeles Sparks  13.617647          12.205882  17.264706   \n",
      "6             Minnesota Lynx  15.970588          11.470588  14.970588   \n",
      "7           New York Liberty  16.117647          11.558824  15.470588   \n",
      "8            Phoenix Mercury  13.529412          11.852941  18.382353   \n",
      "9        Sacramento Monarchs  16.941176          12.029412  15.882353   \n",
      "10  San Antonio Silver Stars  14.764706          11.411765  17.588235   \n",
      "11             Seattle Storm  16.323529          11.941176  15.764706   \n",
      "12        Washington Mystics  16.941176          13.852941  13.323529   \n",
      "\n",
      "     Rebounds  \n",
      "0   71.558824  \n",
      "1   65.852941  \n",
      "2   72.294118  \n",
      "3   68.441176  \n",
      "4   67.323529  \n",
      "5   67.588235  \n",
      "6   66.235294  \n",
      "7   67.176471  \n",
      "8   72.794118  \n",
      "9   64.176471  \n",
      "10  65.794118  \n",
      "11  64.176471  \n",
      "12  67.705882  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_paths = [\"./modified_data/teams.csv\"] \n",
    "\n",
    "columns_to_use = [\"name\", \"d_to\", \"GP\", \"d_stl\", \"d_blk\", \"o_asts\", \"o_reb\", \"d_reb\"]  \n",
    "\n",
    "all_turnovers = []\n",
    "all_steals_blocks = []\n",
    "all_assists = []\n",
    "all_rebounds = []\n",
    "\n",
    "for file_path in file_paths:\n",
    "    df = pd.read_csv(file_path)\n",
    "    df = df[df['year'] == 10]\n",
    "    \n",
    "    if 'd_to' in columns_to_use:\n",
    "        df['Turnovers'] = (df['d_to']) / df['GP']\n",
    "        turnovers_percentages = df.groupby('name')['Turnovers'].mean().reset_index()\n",
    "        all_turnovers.append(turnovers_percentages)\n",
    "    \n",
    "    if 'd_stl' in columns_to_use or 'd_blk' in columns_to_use:\n",
    "        df['Steals and Blocks'] = (df['d_stl'] + df['d_blk']) / df['GP']\n",
    "        steals_blocks_percentages = df.groupby('name')['Steals and Blocks'].mean().reset_index()\n",
    "        all_steals_blocks.append(steals_blocks_percentages)\n",
    "    \n",
    "    if 'o_asts' in columns_to_use:\n",
    "        df['Assists'] = (df['o_asts']) / df['GP']\n",
    "        assists_percentages = df.groupby('name')['Assists'].mean().reset_index()\n",
    "        all_assists.append(assists_percentages)\n",
    "\n",
    "    if 'o_reb' in columns_to_use or 'd_reb' in columns_to_use:\n",
    "        df['Rebounds'] = (df['o_reb'] + df['d_reb']) / df['GP']\n",
    "        rebounds_percentages = df.groupby('name')['Rebounds'].mean().reset_index()\n",
    "        all_rebounds.append(rebounds_percentages)\n",
    "\n",
    "final_turnovers_df = pd.concat(all_turnovers, ignore_index=True)\n",
    "final_steals_blocks_df = pd.concat(all_steals_blocks, ignore_index=True)\n",
    "final_assists_df = pd.concat(all_assists, ignore_index=True)\n",
    "final_rebounds_df = pd.concat(all_rebounds, ignore_index=True)\n",
    "\n",
    "final_combined_df = final_turnovers_df.merge(final_steals_blocks_df, on='name', how='outer')\n",
    "final_combined_df = final_combined_df.merge(final_assists_df, on='name', how='outer')\n",
    "final_combined_df = final_combined_df.merge(final_rebounds_df, on='name', how='outer')\n",
    "\n",
    "final_combined_df.to_csv(\"combined_data.csv\", index=False)\n",
    "\n",
    "print(final_combined_df)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking for null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-13T11:13:58.600120800Z",
     "start_time": "2023-10-13T11:13:58.509918400Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset.isna().sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-13T11:13:58.600120800Z",
     "start_time": "2023-10-13T11:13:58.534633700Z"
    }
   },
   "outputs": [],
   "source": [
    "data_encoded = dataset.copy()\n",
    "\n",
    "# Combine \"AirportFrom\" and \"AirportTo\" columns to create a unified set of airports\n",
    "airports = pd.concat([data_encoded['AirportFrom'], data_encoded['AirportTo']])\n",
    "\n",
    "# Perform label encoding on the combined set of airports\n",
    "label_encoder_airports = LabelEncoder()\n",
    "encoded_airports = label_encoder_airports.fit_transform(airports)\n",
    "\n",
    "# Perform label encoding on the \"Airline\" column\n",
    "label_encoder_airline = LabelEncoder()\n",
    "data_encoded['Airline'] = label_encoder_airline.fit_transform(data_encoded['Airline'])\n",
    "\n",
    "# Update \"AirportFrom\" and \"AirportTo\" columns with the encoded values\n",
    "data_encoded['AirportFrom'] = encoded_airports[:len(data_encoded)]\n",
    "data_encoded['AirportTo'] = encoded_airports[len(data_encoded):]\n",
    "\n",
    "# Remove the \"Flight\" column\n",
    "data_encoded = data_encoded.drop('Flight', axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking the correlation of values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-13T11:13:58.673637500Z",
     "start_time": "2023-10-13T11:13:58.608526200Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset_corr = data_encoded.corr()\n",
    "plt.figure(figsize=(20,20))\n",
    "mask = np.zeros_like(dataset_corr)\n",
    "mask[np.triu_indices_from(mask, k=1)] = True\n",
    "sb.heatmap(dataset_corr, cmap=\"YlGnBu\", annot=True, square=True, mask=mask, fmt='.2f', annot_kws={\"size\": 10});\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All Data Histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-13T11:13:58.608526200Z"
    }
   },
   "outputs": [],
   "source": [
    "data_encoded.hist(bins=30, figsize=(30, 16), sharey=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Relation between the day of the week and delay in flights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-13T11:13:58.608526200Z"
    }
   },
   "outputs": [],
   "source": [
    "sb.catplot(x=\"DayOfWeek\", kind=\"count\", data=data_encoded, hue=\"Class\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Relation between the airline and delay in flights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-13T11:13:58.615769200Z"
    }
   },
   "outputs": [],
   "source": [
    "sb.catplot(x=\"Airline\", kind=\"count\", data=data_encoded, hue=\"Class\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The dataset is slightly imbalanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-13T11:13:58.619556400Z"
    }
   },
   "outputs": [],
   "source": [
    "fraud_df_pie_chart = data_encoded.loc[data_encoded['Class'] == 1.0]\n",
    "not_fraud_df_pie_chart = data_encoded.loc[data_encoded['Class'] == 0.0]\n",
    "\n",
    "array_pie_chart = np.array([len(fraud_df_pie_chart), len(not_fraud_df_pie_chart)])\n",
    "pie_chart_labels = [\"Delayed\", \"Not Delayed\"]\n",
    "\n",
    "plt.pie(array_pie_chart, labels=pie_chart_labels, autopct='%.2f')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After examining the dataset and assessing its characteristics, we conducted a comprehensive analysis. The results revealed a high level of data consistency, with no missing values or notable outliers observed. As a consequence, the dataset demonstrated a remarkable level of readiness for analysis, requiring minimal data preprocessing efforts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-13T11:13:58.621598700Z"
    }
   },
   "outputs": [],
   "source": [
    "data_encoded.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and Test split data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dividimos os dados em conjunto de input e label para os classificadores do Scikit. Label é a coluna Class and input é as restantes colunas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-13T11:13:58.624924700Z"
    }
   },
   "outputs": [],
   "source": [
    "data_encoded['Class'] = data_encoded['Class'].astype('category')\n",
    "\n",
    "col_names = list(data_encoded.columns)\n",
    "col_names.remove('Class')\n",
    "\n",
    "inputs = data_encoded[col_names].values\n",
    "labels = data_encoded['Class'].values"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resumidamente dividi dados em dados de teste e treinamento, mantendo a mesma distribuição das classes inicias, usando 1/4 do dataset original\n",
    "\n",
    "- stratify - para manter a distribuição de classes \n",
    "- train_in - variável que armazena as características de treinamento\n",
    "- test_in - variável que armazena as características de teste\n",
    "- train_classes - armazena as classes dos dados de treinamento\n",
    "- test_classes - armazena as classes dos dados de testes\n",
    "- random_state - para garantir randomness na divisão de dados\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-13T11:13:58.628505Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "(train_in,\n",
    " test_in,\n",
    " train_classes,\n",
    " test_classes) = train_test_split(inputs, labels, test_size=0.25, random_state=1, stratify=labels)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data analyses showed us that our working dataset is unbalanced. We implemented both undersampling and oversampling. Undersampling removes samples from majority categories, while oversampling duplicates samples from minority categories. Generally oversampling is preferred"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conta a ocorrência de cada classe nos conjuntos de treinamento e teste. No training set, tem 224338 de 0 e 180198 de 1. Da um overview da distribuição das classes em cada conunto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-13T11:13:58.628505Z"
    }
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "print(\"---Train Set---\")\n",
    "print(Counter(train_classes))\n",
    "print(\"\\n---Test Set---\")\n",
    "print(Counter(test_classes))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "É usado para balancear os dados. Remove aleatoriamente dados da classe com maior número de dados até que se encontro o equilíbrio que se quer. Undersampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-13T11:13:58.632829Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "rus = RandomUnderSampler()\n",
    "\n",
    "us_inputs, us_labels = rus.fit_resample(train_in, train_classes)\n",
    "\n",
    "print(Counter(us_labels))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Faz oversampling dos dados e conseguimos ver que realmente os dados ficaram equilibradoos nos dados de treino. aumenta o número de linhas, tornando-a mais proporcionsl à classe maioritaria<>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-13T11:13:58.632829Z"
    }
   },
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "ros = SMOTE()\n",
    "\n",
    "os_inputs, os_labels = ros.fit_resample(train_in, train_classes)\n",
    "\n",
    "print(Counter(os_labels))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We used a StandardScaler from SciKit Learn's preprocessing library to standardize the data. Porque é necessário para o K nearest neighbrs e o SVM\n",
    "\n",
    "Fas-se a padronização dos dados para garantir que as características contribuam igualmente para os modelos de machine learning, e evita que uma caraterística em particular dominee o processo de learning da outra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-13T11:13:58.638382Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler  \n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "scaler.fit(train_in)\n",
    "train_in = scaler.fit_transform(train_in)\n",
    "test_in = scaler.fit_transform(test_in)\n",
    "\n",
    "scaler.fit(os_inputs)\n",
    "os_inputs = scaler.fit_transform(os_inputs)\n",
    "\n",
    "scaler.fit(us_inputs)\n",
    "us_inputs = scaler.fit_transform(us_inputs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Nearest Neighbors"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Original Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-13T11:13:58.640483400Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "classifier = KNeighborsClassifier()\n",
    "classifier.fit(train_in, train_classes)\n",
    "y_pred = classifier.predict(test_in)\n",
    "\n",
    "result = confusion_matrix(test_classes, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(result)\n",
    "result1 = classification_report(test_classes, y_pred)\n",
    "print(\"Classification Report:\",)\n",
    "print (result1) \n",
    "\n",
    "knn_og_report = classification_report(test_classes, y_pred,output_dict=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Undersampled Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-13T11:13:58.640483400Z"
    }
   },
   "outputs": [],
   "source": [
    "classifier = KNeighborsClassifier()\n",
    "classifier.fit(us_inputs, us_labels)\n",
    "y_pred = classifier.predict(test_in)\n",
    "\n",
    "knn_confusion_matrix = confusion_matrix(test_classes, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(knn_confusion_matrix)\n",
    "result1 = classification_report(test_classes, y_pred)\n",
    "print(\"Classification Report:\",)\n",
    "print(result1)\n",
    "\n",
    "knn_us_report = classification_report(test_classes, y_pred, output_dict=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Oversampled Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-13T11:13:58.647495200Z"
    }
   },
   "outputs": [],
   "source": [
    "classifier = KNeighborsClassifier()\n",
    "classifier.fit(os_inputs, os_labels)\n",
    "y_pred = classifier.predict(test_in)\n",
    "\n",
    "result = confusion_matrix(test_classes, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(result)\n",
    "result1 = classification_report(test_classes, y_pred)\n",
    "print(\"Classification Report:\",)\n",
    "print (result1)\n",
    "\n",
    "knn_os_report = classification_report(test_classes, y_pred,output_dict=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree Classifier"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Original Dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion matrix:\n",
    "TP FP\n",
    "TN FN\n",
    "FP = False Positive - deu que iam atrasar (1) mas na realidade é 0\n",
    "\n",
    "Precision - mede a proporção de dados corretamente calculado TP/(TP+FP)\n",
    "\n",
    "Accuracy - mede a correção no geral (TP + TN) / (TP + TN + FP + FN).\n",
    "    - em dados não balenciados pode ser misleading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-13T11:13:58.648933300Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dtc = DecisionTreeClassifier()\n",
    "\n",
    "dtc.fit(train_in, train_classes)\n",
    "dtc_prediction = dtc.predict(test_in)\n",
    "\n",
    "dtc_classification_report = classification_report(test_classes, dtc_prediction, output_dict=True)\n",
    "\n",
    "print(\"--- Original dataset ---\\n\")\n",
    "print(\"Confusion matrix:\")\n",
    "print(f\"{confusion_matrix(test_classes, dtc_prediction)}\\n\")\n",
    "print(f\"Classification report:\")\n",
    "print(f\"{classification_report(test_classes, dtc_prediction)}\\n\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Undersampled Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-13T11:13:58.648933300Z"
    }
   },
   "outputs": [],
   "source": [
    "dtc.fit(us_inputs, us_labels)\n",
    "dtc_prediction = dtc.predict(test_in)\n",
    "\n",
    "dtc_us_classification_report = classification_report(test_classes, dtc_prediction, output_dict=True)\n",
    "\n",
    "print(\"--- Undersampled dataset ---\\n\")\n",
    "print(f\"Confusion matrix:\\n{confusion_matrix(test_classes, dtc_prediction)}\\n\")\n",
    "print(f\"Classification report:\\n{classification_report(test_classes, dtc_prediction)}\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Oversampled Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-13T11:13:58.658240300Z"
    }
   },
   "outputs": [],
   "source": [
    "dtc.fit(os_inputs, os_labels)\n",
    "dtc_prediction = dtc.predict(test_in)\n",
    "\n",
    "dtc_os_classification_report = classification_report(test_classes, dtc_prediction, output_dict=True)\n",
    "\n",
    "print(\"--- Oversampled dataset ---\\n\")\n",
    "print(f\"Confusion matrix:\\n{confusion_matrix(test_classes, dtc_prediction)}\\n\")\n",
    "print(f\"Classification report:\\n{classification_report(test_classes, dtc_prediction)}\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Original Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-13T11:13:58.659552700Z"
    }
   },
   "outputs": [],
   "source": [
    "svc = SVC()\n",
    "\n",
    "svc.fit(train_in, train_classes)\n",
    "y_pred = svc.predict(test_in)\n",
    "\n",
    "result = confusion_matrix(test_classes, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(result)\n",
    "result1 = classification_report(test_classes, y_pred)\n",
    "print(\"Classification Report:\",)\n",
    "print (result1) \n",
    "\n",
    "svc_og_report = classification_report(test_classes, y_pred,output_dict=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Undersampled Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-13T11:13:58.659552700Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svc = SVC()\n",
    "\n",
    "svc.fit(us_inputs, us_labels)\n",
    "y_pred = svc.predict(test_in)\n",
    "\n",
    "result = confusion_matrix(test_classes, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(result)\n",
    "result1 = classification_report(test_classes, y_pred)\n",
    "print(\"Classification Report:\",)\n",
    "print (result1) \n",
    "\n",
    "svc_us_report = classification_report(test_classes, y_pred,output_dict=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Oversampled Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-13T11:13:58.665088400Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svc = SVC()\n",
    "\n",
    "svc.fit(os_inputs, os_labels)\n",
    "y_pred = svc.predict(test_in)\n",
    "\n",
    "result = confusion_matrix(test_classes, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(result)\n",
    "result1 = classification_report(test_classes, y_pred)\n",
    "print(\"Classification Report:\",)\n",
    "print (result1) \n",
    "\n",
    "svc_os_report = classification_report(test_classes, y_pred,output_dict=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result Analyses"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-13T11:13:58.665088400Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "all_algorithms_data = pd.read_csv('models_comparison.csv', na_values=['NA'], delimiter=\",\")\n",
    "all_algorithms_data.set_index(\"Model\", inplace=True)\n",
    "\n",
    "sb.heatmap(all_algorithms_data, cmap=\"YlGnBu\", annot=True)\n",
    "plt.xlabel('Results')\n",
    "plt.ylabel('ML Models')\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selected algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-13T11:13:58.668635500Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "selected_algorithms_data = pd.read_csv('models_comparison_selected.csv', na_values=['NA'], delimiter=\",\")\n",
    "selected_algorithms_data.set_index(\"Model\", inplace=True)\n",
    "\n",
    "sb.heatmap(selected_algorithms_data, cmap=\"YlGnBu\", annot=True)\n",
    "plt.xlabel('Results')\n",
    "plt.ylabel('ML Models')\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing Accuracys of each algorythm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-13T11:13:58.668635500Z"
    }
   },
   "outputs": [],
   "source": [
    "selected_algorithms_data = selected_algorithms_data.sort_values(by=['Accuracy'], ascending=False)\n",
    "\n",
    "# Create the bar plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "sb.barplot(x=selected_algorithms_data.index, y='Accuracy', data=selected_algorithms_data, color='#A7226E')\n",
    "\n",
    "# Set the plot title and axis labels\n",
    "plt.title('Accuracy Comparison by Algorithm')\n",
    "plt.xlabel('Model')\n",
    "plt.ylabel('Accuracy')\n",
    "\n",
    "plt.xticks(rotation=90)\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing AUC (Area Under Curve) of each algorythm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-13T11:13:58.668635500Z"
    }
   },
   "outputs": [],
   "source": [
    "selected_algorithms_data = selected_algorithms_data.sort_values(by=['AUC'], ascending=False)\n",
    "\n",
    "# Create the bar plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "sb.barplot(x=selected_algorithms_data.index, y='AUC', data=selected_algorithms_data, color='#FE4365')\n",
    "\n",
    "# Set the plot title and axis labels\n",
    "plt.title('AUC Comparison by Algorithm')\n",
    "plt.xlabel('Model')\n",
    "plt.ylabel('AUC')\n",
    "\n",
    "plt.xticks(rotation=90)\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing Recall of each algorythm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-13T11:13:58.668635500Z"
    }
   },
   "outputs": [],
   "source": [
    "selected_algorithms_data = selected_algorithms_data.sort_values(by=['Recall'], ascending=False)\n",
    "\n",
    "# Create the bar plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "sb.barplot(x=selected_algorithms_data.index, y='Recall', data=selected_algorithms_data, color='#9DE0AD')\n",
    "\n",
    "# Set the plot title and axis labels\n",
    "plt.title('Recall Comparison by Algorithm')\n",
    "plt.xlabel('Model')\n",
    "plt.ylabel('Recall')\n",
    "\n",
    "plt.xticks(rotation=90)\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing Precision of each algorythm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-13T11:13:58.893868Z",
     "start_time": "2023-10-13T11:13:58.673637500Z"
    }
   },
   "outputs": [],
   "source": [
    "selected_algorithms_data = selected_algorithms_data.sort_values(by=['Precision'], ascending=False)\n",
    "\n",
    "# Create the bar plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "sb.barplot(x=selected_algorithms_data.index, y='Precision', data=selected_algorithms_data, color='#F7DB4F')\n",
    "\n",
    "# Set the plot title and axis labels\n",
    "plt.title('Precision Comparison by Algorithm')\n",
    "plt.xlabel('Model')\n",
    "plt.ylabel('Precision')\n",
    "\n",
    "plt.xticks(rotation=90)\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing F1-score of each algorythm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-13T11:13:58.673637500Z"
    }
   },
   "outputs": [],
   "source": [
    "selected_algorithms_data = selected_algorithms_data.sort_values(by=['F1'], ascending=False)\n",
    "\n",
    "# Create the bar plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "sb.barplot(x=selected_algorithms_data.index, y='F1', data=selected_algorithms_data, color='#F26B38')\n",
    "\n",
    "# Set the plot title and axis labels\n",
    "plt.title('F1-Score Comparison by Algorithm')\n",
    "plt.xlabel('Model')\n",
    "plt.ylabel('F1-Score')\n",
    "\n",
    "plt.xticks(rotation=90)\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing Kappa of each algorythm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-13T11:13:58.675723400Z"
    }
   },
   "outputs": [],
   "source": [
    "selected_algorithms_data = selected_algorithms_data.sort_values(by=['Kappa'], ascending=False)\n",
    "\n",
    "# Create the bar plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "sb.barplot(x=selected_algorithms_data.index, y='Kappa', data=selected_algorithms_data, color='#2F9599')\n",
    "\n",
    "# Set the plot title and axis labels\n",
    "plt.title('Kappa Comparison by Algorithm')\n",
    "plt.xlabel('Model')\n",
    "plt.ylabel('Kappa')\n",
    "\n",
    "plt.xticks(rotation=90)\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing Matthews Correlation Coefficient of each algorythm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-13T11:13:58.677950400Z"
    }
   },
   "outputs": [],
   "source": [
    "selected_algorithms_data = selected_algorithms_data.sort_values(by=['MCC'], ascending=False)\n",
    "\n",
    "# Create the bar plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "sb.barplot(x=selected_algorithms_data.index, y='MCC', data=selected_algorithms_data, color='#FF4E50')\n",
    "\n",
    "# Set the plot title and axis labels\n",
    "plt.title('Matthews Correlation Coefficient Comparison by Algorithm')\n",
    "plt.xlabel('Model')\n",
    "plt.ylabel('Matthews Correlation Coefficient')\n",
    "\n",
    "plt.xticks(rotation=90)\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing Training Time (sec) of each algorythm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-13T11:13:58.678506400Z"
    }
   },
   "outputs": [],
   "source": [
    "selected_algorithms_data = selected_algorithms_data.sort_values(by=['TT (Sec)'], ascending=False)\n",
    "\n",
    "# Create the bar plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "sb.barplot(x=selected_algorithms_data.index, y='TT (Sec)', data=selected_algorithms_data, color='#9DE0AD')\n",
    "\n",
    "# Set the plot title and axis labels\n",
    "plt.title('Training Time comparison by Algorithm')\n",
    "plt.xlabel('Model')\n",
    "plt.ylabel('Training Time (Sec)')\n",
    "\n",
    "plt.xticks(rotation=90)\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
